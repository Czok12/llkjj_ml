# LLKJJ ML-Pipeline

**KI-gest√ºtzte Dokumentenverarbeitung** f√ºr die LLKJJ Elektro-Buchhaltungssoftware.

## üöÄ Quick Start

### Installation
```bash
cd llkjj_ml
poetry install --all-extras
```

### Environment Setup
```bash
cp .env.example .env
# Gemini API Key konfigurieren
echo "GEMINI_API_KEY=your_api_key_here" >> .env
```

### Basic Usage
```python
from llkjj_ml.processors import GeminiDirectProcessor

processor = GeminiDirectProcessor()
result = await processor.process_pdf("invoice.pdf")

print(f"Extracted amount: {result.gross_amount}")
print(f"Supplier: {result.supplier_name}")
print(f"Confidence: {result.quality_score}")
```

### Testing
```bash
poetry run pytest                              # Alle Tests
poetry run pytest -m unit                     # Unit Tests
poetry run pytest -m integration              # Integration Tests
poetry run pytest --cov=. --cov-report=html   # Mit Coverage
```

## üì¶ Module-Struktur

### processors/
- **GeminiDirectProcessor**: Hauptprozessor f√ºr PDF-Analyse mit Gemini AI
- **DoclingProcessor**: OCR-basierte Dokumentenverarbeitung
- **UnifiedMLProcessor**: Standard-Pipeline f√ºr neue Features

### quality/
- **QualityAssessor**: Konfidenz-Score-Berechnung
- **ValidationService**: Datenvalidierung

### rag/
- **ChromaDBService**: Vector-basierte √Ñhnlichkeitssuche
- **EmbeddingService**: Text-Embedding-Generierung

## üéØ Features

- ‚úÖ **Gemini-First Pipeline** - Direkte PDF-Analyse mit Google Gemini
- ‚úÖ **OCR Fallback** - Docling-basierte Textextraktion
- ‚úÖ **RAG-System** - ChromaDB f√ºr √Ñhnlichkeitssuche
- ‚úÖ **Quality Assessment** - Automatische Konfidenz-Bewertung
- ‚úÖ **SKR03 Classification** - Deutsche Buchhaltungskonten-Klassifizierung

## üõ†Ô∏è Development

### Code Quality
```bash
poetry run ruff check .      # Linting
poetry run ruff format .     # Code Formatting
poetry run mypy .            # Type Checking
```

---

# Umfassender Projektkontext & Entwicklungsrichtlinien f√ºr KI-Agenten: Das LLKJJ Projekt

**Version: Master Context 1.0**

Dieses Dokument ist die **einzige und ma√ügebliche Quelle der Wahrheit (Single Source of Truth)** f√ºr die KI-gest√ºtzte Entwicklung am LLKJJ-Projekt. Es fasst die Vision, Architektur, technische Blaupause und strategische Ausrichtung zusammen. Halte dich strikt an die hier dargelegten Prinzipien, Architekturen und Anweisungen.

## 1. Vision & Manifest (Das "Warum")

Das Ziel des LLKJJ-Projekts ist die Schaffung einer pers√∂nlichen, hochautomatisierten und intelligenten Buchhaltungs- und Dokumentenmanagement-Engine. Es ist als private, √ºberlegene Alternative zu Standardl√∂sungen konzipiert und exakt auf die Bed√ºrfnisse eines deutschen Elektrohandwerk-Betriebs zugeschnitten.

Es geht nicht darum, eine weitere App zu bauen, sondern eine **ma√ügeschneiderte, hochintegrierte und intelligente Engine**, die den administrativen Aufwand auf ein absolutes Minimum reduziert.

## 2. Leitprinzipien & Strategische Roadmap

### 2.1. Leitprinzipien

1. **Autonomie:** Das System soll lernen, Kontexte verstehen und eigenst√§ndig korrekte Entscheidungen treffen, um manuelle Eingriffe zu minimieren.
2. **Pr√§zision:** Maximale Genauigkeit bei der Datenextraktion und SKR03-Klassifizierung ist das oberste Ziel (>92% Genauigkeit).
3. **Sicherheit:** Da es um sensible Finanzdaten geht, hat die Sicherheit auf allen Ebenen ‚Äì von der Code-Analyse bis zur Datenspeicherung ‚Äì h√∂chste Priorit√§t.
4. **Wartbarkeit:** Eine saubere, entkoppelte Architektur (KISS-Prinzip) ist entscheidend, um das System langfristig pflegen und erweitern zu k√∂nnen.

### 2.2. Strategische Roadmap (KI-Entwicklung)

Die Entwicklung der KI-F√§higkeiten folgt einer zweistufigen Strategie:

1. **Phase 1 (Aktuell): "Gemini-First"-Pipeline**

   * **Ansatz:** Wir nutzen Google's Gemini-Modell (`gemini-2.5d-flash` oder besser) als prim√§res "Gehirn" f√ºr die direkte PDF-Analyse und Datenerfassung. Ein einziger API-Aufruf ersetzt einen komplexen, mehrstufigen Prozess.
   * **Ziel:** Schnelle, qualitativ hochwertige Ergebnisse erzielen und gleichzeitig hochwertige Trainingsdaten (validierte Extraktionen, SKR03-Kontierungen, spaCy-Annotationen) f√ºr die n√§chste Phase sammeln.
2. **Phase 2 (Zukunft): Lokale, autonome KI-L√∂sung**

   * **Ansatz:** Nahtloser √úbergang zu einer von externen APIs unabh√§ngigen L√∂sung.
   * **Ziel:** Einsatz von selbst trainierten **spaCy-Modellen (NER, TextCat)** und einem lokalen **RAG-System (ChromaDB)**, das mit den in Phase 1 gesammelten Daten aufgebaut wird. Deine Arbeit heute bereitet diesen √úbergang vor.

## 3. Gesamtarchitektur (Das "Wie" ‚Äì High Level)

Die Systemarchitektur basiert auf einer strikten Trennung zwischen einem zentralen Backend-Kern und spezialisierten, austauschbaren Plugins.

```
+---------------------------------------------------------------------------------+
|                                 LLKJJ-System                                    |
|                                                                                 |
|  +---------------------------------------------------------------------------+  |
|  |                Workspace 1: Das Backend (Core-System)                     |  |
|  |---------------------------------------------------------------------------|  |
|  | [FastAPI] -> API Routers -> [Service Schicht] -> [Repository] -> PostgreSQL |  |
|  |      ^                (Business Logic)      (SQLAlchemy)      (Struktur)  |  |
|  |      |                                                                    |  |
|  |      +------------------(Definierte Schnittstellen)-----------------------+  |
|  +------------------------------------|----------------------------------------+  |
|                                       |                                         |
|      +--------------------------------+--------------------------------+        |
|      |                                |                                |        |
|      v                                v                                v        |
| +-------------------------+  +-------------------------+  +-------------------------+ |
| | Workspace 2:            |  | Workspace 3:            |  | Workspace 4:            | |
| | ML-Pipeline             |  | E-Invoice-System        |  | Export-System           | |
| | (`llkjj_ml_plugin`)     |  | (`llkjj_efaktura`)      |  | (`llkjj_export`)        | |
| |-------------------------|  |-------------------------|  |-------------------------| |
| | - OCR (Docling)         |  | - XRechnung / UBL XML   |  | - DATEV CSV Export      | |
| | - Gemini-First (aktiv)  |  | - PDF/A-3 Generierung   |  | - JSON / Standard CSV   | |
| | - RAG (ChromaDB)        |  | - KoSIT-Validierung     |  | - Universelle Schemas   | |
| +-------------------------+  +-------------------------+  +-------------------------+ |
+-------------------------------------------------------------------------------------+
```

- **Workspace 1: Das Backend (Core-System):** Der zentrale Orchestrator. Stellt die REST-API bereit, verwaltet Benutzer und Daten in PostgreSQL und kommuniziert mit den Plugins √ºber definierte Schnittstellen.
- **Workspace 2: Die ML-Pipeline (`llkjj_ml_plugin`):** Das "Gehirn". Verarbeitet eine PDF-Datei und gibt ein strukturiertes, klassifiziertes Ergebnis zur√ºck. **Dies ist dein prim√§rer Fokus.**
- **Workspace 3: Das E-Invoice-System (`llkjj_efaktura`):** Spezialist f√ºr die Erstellung gesetzeskonformer E-Rechnungen (XRechnung, Factur-X).
- **Workspace 4: Das Export-System (`llkjj_export`):** Stellt Daten in verschiedenen Formaten (z.B. DATEV-CSV) f√ºr externe Systeme bereit.

## 4. Detailarchitektur & Workflow des ML-Plugins (`llkjj_ml_plugin`)

### 4.1. Interne Komponenten & Interaktion

Das ML-Plugin ist als hochgradig modulares, eigenst√§ndiges Paket konzipiert.

### 4.2. Haupt-Workflow (Gemini-First)

Der Standardprozess wird durch `GeminiDirectProcessor` gesteuert:

1. **Eingabe & Validierung:** Eine PDF-Datei wird an `process_pdf_gemini_first` √ºbergeben und gepr√ºft.
2. **Gemini-Analyse:** Die PDF wird an die Google Gemini API gesendet. Ein spezifischer Prompt instruiert das Modell, alle Daten in einem strukturierten JSON zu extrahieren.
3. **Schema-Validierung:** Die JSON-Antwort von Gemini wird strikt gegen das Pydantic-Schema `GeminiExtractionResult` validiert. Dies ist ein kritischer Qualit√§tssicherungsschritt.
4. **RAG-Anreicherung:** Die von Gemini vorgeschlagenen SKR03-Konten werden durch das lokale RAG-System (ChromaDB) verfeinert und validiert, indem √§hnliche, bereits best√§tigte Buchungen gesucht werden.
5. **Qualit√§tsbewertung:** Der `QualityAssessor` berechnet einen finalen Konfidenz-Score.
6. **Trainingsdaten-Generierung:** Es werden korrigierte spaCy-Annotationen erzeugt und validierte Daten in ChromaDB gespeichert, um den Feedback-Loop zu schlie√üen und das System kontinuierlich zu verbessern.
7. **Ausgabe:** Ein Pydantic-validiertes **`ProcessingResult`-Objekt** wird zur√ºckgegeben. Dies ist die einzige garantierte Schnittstelle nach au√üen.

### 4.3. Wichtige technische Details & Design-Entscheidungen

- **Datenvertrag:** Das `ProcessingResult`-Modell ist der **stabile, √∂ffentliche Datenvertrag** des ML-Plugins. Interne √Ñnderungen d√ºrfen dieses Schema nicht brechen.
- **Fehlerbehandlung:** Wenn ein Schritt in der Gemini-Pipeline fehlschl√§gt (API-Fehler, Validierungsfehler), wird der Prozess mit einer `RuntimeError` abgebrochen. **Es gibt keinen automatischen Fallback auf die Docling-Methode.** Dies ist eine bewusste Entscheidung, um Fehler in der prim√§ren Pipeline sichtbar zu machen und zu beheben, anstatt sie zu verschleiern.
- **Ressourcen-Management:** Ein `ResourceManager` (Singleton-Pattern) stellt sicher, dass ressourcenintensive Modelle (z.B. `SentenceTransformer`) nur einmal geladen werden, um den Speicherverbrauch zu minimieren.
- **Datenbanken:**
  - **PostgreSQL (im Backend):** Speichert alle strukturierten Gesch√§ftsdaten. Der Zugriff erfolgt via SQLAlchemy 2.0 (async).
  - **ChromaDB (im ML-Plugin):** Dient als Vektordatenbank f√ºr das RAG-System und das "Langzeitged√§chtnis".
- **Sicherheit:**
  - **Authentifizierung:** Basiert auf JWT mit Argon2-gehashten Passw√∂rtern.
  - **Auditing:** Eine `SecurityAuditor`-Klasse (`Bandit`, `Safety`) ist Teil der CI-Pipeline.
  - **Secret Management:** Sensible Schl√ºssel werden "at rest" mit AES-256 verschl√ºsselt.

## 5. Anweisungen f√ºr die KI-gest√ºtzte Entwicklung (Deine Mission)

### 5.1. Generelle Anweisungen ("Golden Rules")

1. **Sprache:** Der gesamte Code, alle Kommentare und die Dokumentation sind auf **Deutsch**, um die Dom√§nensprache (deutsche Buchhaltung) konsistent abzubilden.
2. **Architektur respektieren:** Halte dich strikt an die Trennung von Backend-Kern und Plugins. Keine direkten Abh√§ngigkeiten zwischen den Workspaces, au√üer √ºber die definierten Schnittstellen (`ProcessingResult` etc.).
3. **Sicherheit zuerst:** Jeder neue Code muss sicher sein. Vermeide hartcodierte Secrets, validiere alle Eingaben und nutze die bereitgestellten Sicherheits-Utilities.
4. **Typsicherheit:** Der gesamte Code muss `MyPy --strict` konform sein.
5. **Testen:** F√ºr neue Funktionen m√ºssen entsprechende `pytest`-Tests geschrieben werden.
6. **Fokus:** Deine Hauptaufgabe ist es, die "Gemini-First"-Pipeline zu verbessern und gleichzeitig den √úbergang zu Phase 2 (lokale Modelle) vorzubereiten. Die Qualit√§t und Konsistenz der gesammelten Trainingsdaten ist wichtiger als kurzfristige Performance-Hacks.

### 5.2. Anweisungen f√ºr Deinen Workspace: Die ML-Pipeline (`llkjj_ml_plugin`)

- **Dein Kernziel:** Eine PDF-Datei so pr√§zise wie m√∂glich in ein strukturiertes, SKR03-klassifiziertes `ProcessingResult`-Objekt zu verwandeln.
- **Dein Kontext:** Du bist ein Experte f√ºr Machine Learning, NLP (spaCy, Transformers), Computer Vision, Vektordatenbanken (ChromaDB) und die Integration von LLMs wie Gemini.
- **Deine Hauptaufgaben:** Verbesserung der Extraktions-Pipeline (`GeminiDirectProcessor`), Optimierung der Klassifizierungsmodelle, Implementierung von Feature Engineering und St√§rkung des RAG-Systems.
- **Deine Interaktionen und Grenzen:**
  - Deine **einzige Schnittstelle** zum Backend ist das `ProcessingResult`-Schema.
  - Du darfst **keine direkten Abh√§ngigkeiten** zum Backend-Code (`Workspace 1`) oder dessen PostgreSQL-Datenbank haben. Du agierst als eigenst√§ndige Blackbox.
  - Deine eigene Persistenz (z.B. f√ºr `ChromaDB`) verwaltest du in deinem eigenen Verzeichnis (z.B. `data/vectors`).

---

## Kompatibilit√§t & Fehlerbehandlung (Shims)

Zur Stabilisierung der Tests und f√ºr eine robuste Fehlerbehandlung wurden minimalinvasive Kompatibilit√§tsshims erg√§nzt. Diese √§ndern keine Kernlogik, sondern verbessern Eingabe-/R√ºckgabeformate und Fehlertoleranz:

- DoclingProcessor
  - Konstruktor akzeptiert zus√§tzlich die Alias-Flags `german_ner_enabled` bzw. `german_ner` (intern auf `german_optimized` gemappt).
  - `process_pdf` gibt bei Erfolg ein Resultat mit `success=True`, `text` (Alias f√ºr `raw_text`) sowie `quality_score` zur√ºck. Bei Fehlern wird nicht geworfen, sondern `{success: False, error: ...}` zur√ºckgegeben.
  - `_normalize_german_headers` liefert eine Liste normalisierter Header (gleiche L√§nge wie Eingabe) f√ºr teststabile Verarbeitung.
  - `_apply_german_ner` akzeptiert neben `dict` auch `str` als Eingabe.

- HybridResult (Hybrid Intelligence)
  - Zus√§tzliches Feld `cost`, das `cost_estimate` spiegelt. Beide Felder werden beim Initialisieren synchronisiert.

Diese Anpassungen dienen der Testkompatibilit√§t und erh√∂hen die Nachvollziehbarkeit f√ºr Entwickler und KI‚ÄëAgenten.
