# LLKJJ ML Pipeline - Roadmap & TODO (Gemini-Strategie 18.08.2025)

## üéØ **PRIORIT√ÑT 1: GEMINI-PIPELINE PRODUKTIONSREIF MACHEN (STRATEGIC PRIORITY)**

### **Strategische Vision: Phase 1 ‚Üí 2 Transition**
- **Phase 1 (JETZT)**: Gemini AI als produktive Intelligence-Engine
- **Phase 2 (SP√ÑTER)**: Nahtloser √úbergang zu lokaler spaCy/RAG-Autonomie
- **Kernziel**: Jede verarbeitete Rechnung = Trainingsdaten f√ºr zuk√ºnftige Unabh√§ngigkeit

### **Sofort-Umsetzung (A-Priorit√§t)**

#### **A1: Pydantic-Validierung f√ºr Gemini-Antworten (KRITISCH)**
- [x] **Schema-Definition**: `src/models/gemini_schemas.py` erstellen ‚úÖ
  - [x] `GeminiInvoiceHeader(BaseModel)` - Rechnungskopf-Schema ‚úÖ
  - [x] `GeminiLineItem(BaseModel)` - Rechnungspositions-Schema ‚úÖ
  - [x] `GeminiExtractionResult(BaseModel)` - Vollst√§ndiges Response-Schema ‚úÖ
- [x] **Integration in GeminiDirectProcessor**: Sofortige Validierung nach API-Response ‚úÖ
  - [x] `validated_data = GeminiExtractionResult(**json.loads(response_text))` ‚úÖ
  - [x] Fehlerbehandlung f√ºr ung√ºltige Gemini-Responses ‚úÖ
- [x] **Qualit√§tssicherung**: Nur validierte Daten in ProcessingResult ‚úÖ

#### **A2: Trainingsdaten-Persistierung (DATENSCHATZ)**
- [x] **spaCy-Training-Export**: Nach jeder erfolgreichen Verarbeitung ‚úÖ
  - [x] JSONL-Format: `data/training/gemini_spacy_annotations.jsonl` ‚úÖ
  - [x] Annotationen + raw_text f√ºr zuk√ºnftiges NER/TextCat-Training ‚úÖ
- [x] **RAG-System-Population**: ChromaDB mit Gemini-Klassifizierungen ‚úÖ
  - [x] Jede Position ‚Üí ChromaDB-Dokument mit Metadatum `"source": "gemini_validated"` ‚úÖ
  - [x] Embedding-Vektor f√ºr √Ñhnlichkeitssuche ‚úÖ
- [x] **Audit-Trail**: GoBD-konforme Speicherung in `logs/audit_gemini.jsonl` ‚úÖ

#### **A3: Performance-Optimierung**
- [x] **Async Gemini-Processing**: `AsyncGeminiDirectProcessor` ‚úÖ
  - [x] `asyncio.gather()` f√ºr Batch-Verarbeitung ‚úÖ
  - [x] `asyncio.Semaphore(3)` f√ºr API-Rate-Limiting ‚úÖ
- [x] **PDF-Hash-Caching**: SQLite-Cache gegen Duplikate ‚úÖ
  - [x] SHA256-Hash vor API-Call ‚úÖ
  - [x] Cache-Hit ‚Üí sofortiges Ergebnis (0ms statt 5000ms) ‚úÖ

### **Architektur-Vorbereitung f√ºr Phase 2 (B-Priorit√§t)**

#### **B1: Strategy-Pattern f√ºr nahtlose Transition**
- [x] **Abstrakte ProcessingStrategy**: Interface f√ºr alle Engines ‚úÖ
- [x] **GeminiStrategy**: Aktueller GeminiDirectProcessor ‚úÖ
- [x] **UnifiedProcessor**: Engine-Auswahl zur Laufzeit ‚úÖ
- [x] **Vorbereitung SpacyRagStrategy**: Platzhalter f√ºr Phase 2 ‚úÖ

#### **B2: spaCy-Training-Pipeline**
- [ ] **Automated Training**: Trigger bei X gesammelten Beispielen
- [ ] **Model-Versioning**: Inkrementelle Verbesserung lokaler Modelle
- [ ] **Performance-Benchmarking**: Gemini vs. spaCy Genauigkeitsvergleich

#### **B3: RAG-System Optimierung (INTELLIGENTES GED√ÑCHTNIS)**
**Strategische Bedeutung**: Das RAG-System ist das Herzst√ºck der zuk√ºnftigen autonomen Pipeline - von einfacher √Ñhnlichkeitssuche zum intelligenten Langzeitged√§chtnis.

##### **Phase 1: Robuste Dateneinspeisung (Sofort)**
- [ ] **Validierungs-Status in ChromaDB-Metadaten**
  - [ ] `validation_status`: `"ai_suggested"` | `"user_confirmed"` | `"user_corrected"` | `"system_flagged"`
  - [ ] Grundlage f√ºr Qualit√§tsgewichtung und Selbstkorrektur
- [ ] **Feedback-Loop Implementation**
  - [ ] Backend-Endpunkt `/feedback` f√ºr Benutzerkorrekturen
  - [ ] ChromaDB-Update mit korrigierten Klassifizierungen
  - [ ] Konfidenz auf 1.0 setzen f√ºr `user_corrected`-Eintr√§ge
- [ ] **Kontext-Anreicherung der Vektor-Dokumente**
  - [ ] Von: `"Lieferant: X | Artikel: Y"`
  - [ ] Zu: `"Artikel: Y, Menge: Z, Preis: N EUR. Lieferant: X (Typ). Kategorie: K."`
  - [ ] Embedding versteht Kontext: Einzelwerkzeug vs. Verbrauchsmaterial

##### **Phase 2: Intelligenter Abruf (Hybrid Search)**
- [ ] **Mehrstufige Suche mit Metadaten-Filterung**
  - [ ] ChromaDB `where`-Filter f√ºr Lieferanten-spezifische Suche
  - [ ] Gewichtung: `user_corrected/confirmed` Eintr√§ge √ó 1.5 Faktor
  - [ ] Vorfilterung reduziert "false positives" drastisch
- [ ] **Dynamische √Ñhnlichkeitsschwelle**
  - [ ] Hohe Schwelle (0.7) bei vielen validierten Lieferanten-Daten
  - [ ] Niedrige Schwelle (0.5) bei unbekannten Artikeln
  - [ ] Adaptive Pr√§zision vs. Recall-Balance

##### **Phase 3: Explainable AI & Selbstkorrektur**
- [ ] **Erweiterte Begr√ºndungs-Engine**
  - [ ] XAI-Reasoning: "Vorschlag 3400. Regel-Konfidenz 0.8 + 3 √§hnliche best√§tigte Sonepar-Buchungen (√ò 0.85)"
  - [ ] Frontend-Integration f√ºr Benutzervertrauen
- [ ] **Proaktives Inkonsistenz-Flagging**
  - [ ] Top-3 RAG-Treffer ‚Üí 3 verschiedene SKR03-Konten = `system_flagged`
  - [ ] Automatische Konfidenz-Reduktion bei Mehrdeutigkeit
  - [ ] "Warnung: √Ñhnliche Artikel unterschiedlich kontiert. Bitte pr√ºfen."

**Strategischer Nutzen**:
- ‚úÖ Kontinuierliches Lernen aus Benutzerfeedback
- ‚úÖ Selbstheilende Datenbasis ("vergiftete" Daten werden korrigiert)
- ‚úÖ Kontextbewusste Klassifizierung (Anlageverm√∂gen vs. Verbrauchsmaterial)
- ‚úÖ Vorbereitung f√ºr Phase 2: Lokales "intelligentes Ged√§chtnis" ohne Gemini-Abh√§ngigkeit

---

## üèóÔ∏è **PRIORIT√ÑT 2: STRUKTUR-KONSOLIDIERUNG (KANN WARTEN)**

### **Problem Analyse (Urspr√ºnglicher Plan)**
- **Redundante Struktur**: `src/` UND `ml_service/` innerhalb eines Plugin-Pakets
- **Abh√§ngigkeits-Chaos**: `ml_service/` importiert von `src/` (4 Imports gefunden)
- **Gegen KISS-Prinzip**: Zwei Quellcode-Verzeichnisse f√ºr ein Paket
- **Wartungslast**: Doppelte Implementierungen und unklare Zust√§ndigkeiten

### **Konsolidierungsplan: Alles ‚Üí `src/`**

#### **Phase 1: Struktur-Analyse & Backup (2h)**
- [ ] **Abh√§ngigkeits-Mapping**: Vollst√§ndige Analyse aller Import-Beziehungen
  - [ ] `grep -r "from ml_service" src/` ‚Üí R√ºckw√§rts-Dependencies pr√ºfen
  - [ ] `grep -r "from src" ml_service/` ‚Üí Vorw√§rts-Dependencies dokumentieren
  - [ ] Zirkul√§re Imports identifizieren und dokumentieren
- [ ] **Backup erstellen**: `git branch backup-before-consolidation`
- [ ] **Funktionalit√§ts-Audit**: Was macht `ml_service/` was `src/` nicht kann?

#### **Phase 2: ml_service/ ‚Üí src/ Migration (4h)**
- [ ] **CLI Migration**: `ml_service/cli.py` ‚Üí `src/cli/ml_service_cli.py`
  - [ ] Imports auf src/-Struktur umstellen
  - [ ] `__main__.py` Funktionalit√§t nach `src/cli/` verschieben
- [ ] **Processor Migration**: `ml_service/processor.py` ‚Üí `src/processor/ml_service_processor.py`
  - [ ] 4 src/-Imports aufl√∂sen (bereits dokumentiert)
  - [ ] MLSettings Integration mit bestehender src/config.py
  - [ ] ProcessingResult Deduplizierung
- [ ] **Config Migration**: `ml_service/config.py` ‚Üí `src/config/ml_service_config.py`
  - [ ] MLSettings mit bestehender Config-Klasse mergen
  - [ ] Environment-Variable Handling vereinheitlichen

#### **Phase 3: pyproject.toml f√ºr src/-Layout (1h)**
- [ ] **Poetry Konfiguration**:
  ```toml
  packages = [{ include = "llkjj_ml", from = "src" }]
  ```
- [ ] **Entry Points aktualisieren**:
  ```toml
  [project.scripts]
  llkjj-ml = "src.main:main"
  ```
- [ ] **Package-Struktur validieren**: `poetry install` testen

#### **Phase 4: Import-Cleanup & Tests (2h)**
- [ ] **Import-Pfade reparieren**: Alle `from ml_service.` ‚Üí `from src.`
- [ ] **main.py aktualisieren**: CLI-Integration f√ºr konsolidierte Struktur
- [ ] **Tests reparieren**: `ml_service/tests/` ‚Üí `tests/ml_service/`
- [ ] **Funktionalit√§ts-Test**: Vollst√§ndige Pipeline-Validation

#### **Phase 5: Aufr√§umen & Dokumentation (1h)**
- [ ] **ml_service/ Verzeichnis entfernen**: Nach erfolgreicher Migration
- [ ] **README.md aktualisieren**: Neue src/-Struktur dokumentieren
- [ ] **API_DOCUMENTATION.py**: Import-Pfade korrigieren
- [ ] **Commit & Tag**: `git tag v4.0.0-consolidated`

### **Erfolgs-Kriterien**
- ‚úÖ Ein einziges Quellcode-Verzeichnis: `src/`
- ‚úÖ Keine Import-Abh√§ngigkeiten zwischen ehemaligen Verzeichnissen
- ‚úÖ Alle Tests bestehen nach Konsolidierung
- ‚úÖ CLI-Funktionalit√§t vollst√§ndig erhalten
- ‚úÖ Poetry build/install funktioniert einwandfrei

### **Rollback-Plan**
- **Git Branch**: `backup-before-consolidation` f√ºr sofortigen Rollback
- **Validierungs-Skript**: `poetry run python -c "from src import *; print('Import OK')"`

---

## üìã **PROJEKTSTATUS-√úBERSICHT** (nach Konsolidierung)

**Aktuelle Version:** 3.0.0 ‚Üí 4.0.0 (Konsolidierte KISS-Architektur)
```markdown
- [ ] Sprint 1 ‚Äî Critical Foundation (26h)
  - [ ] Learning Rate Optimization (6h) ‚Äî `spacy_training/ner_training.py`, `spacy_training/cat_trainer.py`
    - [ ] Integrate ProductionLearningRateScheduler into `BaseTrainer`
    - [ ] Add `_update_learning_rate()` hook and call before each epoch
    - [ ] Update spaCy optimizer learn_rate from scheduler
    - [ ] Run LR demo and compare convergence on Sonepar sample invoices
  - [ ] Deutsche Rechnungs-Augmentation (12h) ‚Äî `spacy_training/pipeline.py`, `unified_processor.py`
    - [ ] Implement `GermanElektroAugmenter` (synonyms, date/currency formats)
    - [ ] Simulate OCR noise (character swaps, missing umlauts)
    - [ ] Integrate augmentation pipeline with Gemini synthetic data generation
    - [ ] Generate 500+ augmented training samples and save to `data/training/augmented/`
  - [ ] SKR03 Business Metrics (8h) ‚Äî `spacy_training/ner_training.py`, `spacy_training/cat_trainer.py`
    - [ ] Extend `TrainingMetrics` with `invoice_completeness`, `skr03_accuracy`, `entity_coverage`
    - [ ] Implement invoice completeness & date-consistency checks
    - [ ] Add per-entity confusion matrix output and persistence
    - [ ] Wire metrics into existing logging and `save_training_metrics()`

- [ ] Sprint 2 ‚Äî High-Value Improvements (22h)
  - [ ] Smart Checkpointing & Early Stopping (4h) ‚Äî `src/trainer.py`
    - [ ] Implement checkpoint save/resume in `BaseTrainer`
    - [ ] Add early stopping based on validation loss patience
    - [ ] Add CLI flag to resume from checkpoint
  - [ ] Stratified Cross-Validation (8h) ‚Äî `spacy_training/pipeline.py`
    - [ ] Implement stratified K-Fold wrapper for NER/TextCat
    - [ ] Produce aggregated CV reports (mean/std of metrics)
    - [ ] Integrate CV into `TrainingPipeline.run_full_pipeline()` optional mode
  - [ ] Gemini Training Enhancement (10h) ‚Äî `unified_processor.py`, training pipeline
    - [ ] Add Gemini prompts to synthesize annotated invoice examples
    - [ ] Implement quality checks and automatic correction suggestions
    - [ ] Integrate synthesized data into augmentation pipeline with provenance

- [ ] Sprint 3 ‚Äî Performance Boost (18h)
  - [ ] Transformer-Integration (16h) ‚Äî `spacy_training/ner_training.py`
    - [ ] Evaluate `spacy-transformers` with a German BERT model
    - [ ] Implement optional transformer-backed pipeline (config toggle)
    - [ ] Benchmark accuracy vs inference speed and memory
  - [ ] Hyperparameter Automation (2h setup) ‚Äî `spacy_training/pipeline.py`
    - [ ] Add minimal Optuna integration for LR & batch size search
    - [ ] Persist best-trial params and integrate into training config

- [ ] Validation & Deliverables
  - [ ] After Sprint 1: compare baseline vs new models (F1, time)
  - [ ] After Sprint 2: validate resume/checkpoint behavior and CV results
  - [ ] After Sprint 3: run transformer benchmark and decide rollout

- [ ] Immediate / Pre-work (do these before Sprint 1)
  - [ ] Backup current models to `data/models_backup/` (mandatory)
  - [ ] Run `poetry run python production_lr_scheduler.py` to verify scheduler
  - [ ] Prepare a small Sonepar sample set in `test_pdfs/` for quick iteration

- [ ] Validation commands (examples)
  - [ ] `poetry run python main.py process test_pdfs/Sonepar_test3.pdf --validate-metrics`
  - [ ] `poetry run python demo_enhanced_training.py --compare-baseline`

- [ ] Risk & Rollback
  - [ ] Each sprint must include a rollback test (load previous model + metrics)
  - [ ] Store checkpoints and tags in `data/models_backup/` with timestamped folders

- [ ] Notes
  - Estimated total effort (Sprints 1-3): ~66h (focused) ‚Äî can be reduced to ~48h if Transformer step deferred
  - Keep new features opt-in via config flags to preserve backward compatibility
  - Prefer incremental PRs per subtask for easy review and rollback

```
```markdown
